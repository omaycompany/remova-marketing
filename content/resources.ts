export interface Resource {
    slug: string;
    title: string;
    type: "guide" | "checklist" | "template" | "whitepaper" | "toolkit";
    metaTitle: string;
    metaDescription: string;
    description: string;
    sections: { heading: string; content: string }[];
}

const r = (slug: string, title: string, type: Resource["type"], description: string, sections: [string, string][]): Resource => ({
    slug, title, type,
    metaTitle: `${title} | Free Resource | Remova`,
    metaDescription: `${description.slice(0, 150)}. Free enterprise AI resource from Remova.`,
    description,
    sections: sections.map(([h, c]) => ({ heading: h, content: c })),
});

export const resources: Resource[] = [
    r("ai-governance-starter-kit", "AI Governance Starter Kit", "toolkit", "Everything you need to launch an AI governance program: policy templates, evaluation criteria, implementation timeline, and success metrics.", [["What's Included", "This starter kit contains: AI acceptable use policy template, vendor evaluation scorecard, 8-week implementation timeline, department budget planning worksheet, and KPI tracking template."], ["Who It's For", "CISOs, CIOs, and IT leaders launching their first AI governance program. Also valuable for compliance officers mapping AI controls to regulatory frameworks."], ["How to Use It", "Start with the policy template (customize for your org), then use the evaluation scorecard to select a platform, follow the 8-week timeline, and track progress with the KPI template."], ["Expected Outcomes", "Organizations using this starter kit typically achieve: governed AI access within 8 weeks, 90%+ policy compliance within 60 days, and measurable productivity gains within the first quarter."]]),
    r("enterprise-ai-security-checklist", "Enterprise AI Security Checklist", "checklist", "50-point security checklist for enterprise AI deployments. Cover every security domain from network to identity to data protection.", [["Network Security (10 points)", "TLS 1.3 for all AI traffic, VPN/private link for on-prem, network segmentation, DDoS protection, egress filtering, DNS security, certificate management, network monitoring, firewall rules, and intrusion detection."], ["Application Security (10 points)", "Input validation, output screening, rate limiting, session management, API authentication, error handling, dependency scanning, code signing, CSRF protection, and content security policy."], ["Data Security (15 points)", "PII redaction, zero-history architecture, encryption at rest, encryption in transit, DLP policies, data classification, access controls, audit logging, backup procedures, retention policies, data sovereignty, anonymization, consent management, breach notification, and privacy impact assessment."], ["Identity Security (15 points)", "SSO integration, MFA enforcement, RBAC implementation, least privilege access, API key management, service account governance, session timeouts, access reviews, provisioning automation, deprovisioning automation, password policies, privileged access management, directory integration, conditional access, and identity monitoring."]]),
    r("ai-vendor-evaluation-scorecard", "AI Vendor Evaluation Scorecard", "template", "Structured scorecard for evaluating AI platform vendors across security, compliance, capability, cost, and support dimensions.", [["Security Criteria (25%)", "Rate vendors 1-5 on: zero-history architecture, PII redaction capabilities, guardrail sophistication, encryption standards, on-premises option, SOC 2 certification, penetration testing frequency, incident response SLA, and vulnerability disclosure program."], ["Compliance Criteria (25%)", "Rate on: GDPR compliance, HIPAA readiness, SOX compatibility, EU AI Act alignment, NIST AI RMF coverage, audit log exports, data sovereignty controls, BAA availability, and DPA terms."], ["Capability Criteria (25%)", "Rate on: number of AI models, model routing intelligence, RAG/knowledge base, SSO integration, department management, budget controls, API access, customization options, and user experience."], ["Cost & Support (25%)", "Rate on: pricing transparency, cost normalization, budget controls, billing granularity, support response time, documentation quality, onboarding assistance, community resources, and roadmap visibility."]]),
    r("hipaa-ai-compliance-guide", "HIPAA Compliance Guide for Enterprise AI", "guide", "Comprehensive HIPAA compliance guide for healthcare organizations deploying AI. Technical safeguards, administrative controls, and BAA requirements.", [["HIPAA and AI Overview", "HIPAA's Privacy Rule, Security Rule, and Breach Notification Rule all apply to AI interactions containing PHI. This guide maps each HIPAA requirement to specific AI governance controls."], ["Technical Safeguards", "Access controls (RBAC by clinical role), audit controls (comprehensive logging), integrity controls (data validation), transmission security (TLS 1.3), and authentication (SSO with MFA)."], ["Administrative Controls", "Security management process, workforce training, information access management, security incident procedures, contingency planning, evaluation, and BAA management."], ["Implementation Checklist", "15-step implementation checklist: conduct risk assessment, select HIPAA-compliant platform, execute BAA, configure PHI detection, implement access controls, enable audit logging, train staff, test PHI detection, document procedures, conduct security awareness training, establish incident response, implement breach notification, perform ongoing monitoring, conduct annual audits, and update risk assessment."]]),
    r("gdpr-ai-compliance-template", "GDPR Compliance Template for AI Systems", "template", "GDPR compliance documentation template for enterprise AI. DPIA template, processing records, and consent management frameworks.", [["Data Protection Impact Assessment", "Structured DPIA template for AI systems: describe processing, assess necessity, identify risks, document mitigations, and consultation requirements. Pre-filled with AI-specific risk categories."], ["Records of Processing", "Template for Article 30 records: purpose of processing, categories of data subjects, categories of personal data, recipients, international transfers, retention periods, and security measures."], ["Lawful Basis Documentation", "Framework for documenting lawful basis for AI data processing. Templates for: legitimate interest assessments, consent records, and contractual necessity documentation."], ["Data Subject Rights", "Procedures for handling data subject requests in AI context: access requests, erasure requests, portability requests, and objection to automated processing. Zero-history architecture simplifies most requests."]]),
    r("ai-budget-planning-worksheet", "AI Budget Planning Worksheet", "template", "Plan and allocate AI budgets across departments. Includes cost estimation formulas, allocation models, and ROI tracking.", [["Cost Estimation", "Estimate AI costs based on: user count, queries per user per day, average tokens per query, model mix (% premium vs. lightweight), and provider pricing. Includes formulas for each calculation."], ["Allocation Models", "Three allocation approaches: equal (same budget per department), proportional (budget by headcount), and value-based (budget by expected ROI). Worksheet includes templates for each model."], ["Budget Controls", "Configure: hard cap per department, alert thresholds (75%, 90%), auto-stop logic, rollover policies, and emergency increase procedures. Map each control to platform settings."], ["ROI Tracking", "Monthly ROI tracking template: AI costs, time savings (hours × hourly rate), quality improvements (error reduction × cost per error), and incident prevention (risk reduction × potential cost). Net ROI formula with worked examples."]]),
    r("ai-acceptable-use-policy", "AI Acceptable Use Policy Template", "template", "Ready-to-customize AI acceptable use policy for enterprises. Covers approved tools, data handling, prohibited uses, and enforcement.", [["Policy Framework", "Complete policy structure: purpose, scope, definitions, approved tools, prohibited activities, data classification for AI, approval processes, monitoring and enforcement, training requirements, and policy maintenance."], ["Data Classification for AI", "Four-tier classification: Restricted (never share with AI — SSNs, passwords, trade secrets), Confidential (share only with governed AI — client data, financials), Internal (share with governed AI — project names, org info), Public (unrestricted — general knowledge, public info)."], ["Role-Specific Guidelines", "Customizable sections for: executives, engineering, marketing, HR, legal, finance, sales, and operations. Each role gets specific do's and don'ts relevant to their function."], ["Enforcement Procedures", "Progressive enforcement: nudge notification (first violation), written warning (second), temporary access restriction (third), permanent restriction (fourth). Technical enforcement through guardrails is always preferred over manual enforcement."]]),
    r("nist-ai-rmf-mapping-guide", "NIST AI RMF Mapping Guide", "guide", "Map your AI governance controls to NIST AI Risk Management Framework functions. Govern, Map, Measure, and Manage mapped to practical controls.", [["Govern Function Mapping", "Map organizational governance to NIST Govern: AI governance committee (GV-1), AI policy development (GV-2), risk management integration (GV-3), organizational culture (GV-4), and legal/regulatory compliance (GV-5)."], ["Map Function Mapping", "Map risk identification to NIST Map: AI system inventory (MP-1), intended use documentation (MP-2), risk categorization (MP-3), benefits/costs assessment (MP-4), and impact identification (MP-5)."], ["Measure Function Mapping", "Map risk assessment to NIST Measure: performance metrics (MS-1), safety evaluation (MS-2), fairness assessment (MS-3), security testing (MS-4), and explainability review (MS-5)."], ["Manage Function Mapping", "Map risk treatment to NIST Manage: risk prioritization (MG-1), control implementation (MG-2), monitoring (MG-3), incident response (MG-4), and continuous improvement (MG-5). Platform controls like guardrails, DLP, and audit logs map directly."]]),
    r("eu-ai-act-readiness-assessment", "EU AI Act Readiness Assessment", "checklist", "Assess your organization's readiness for EU AI Act compliance. Risk classification, gap analysis, and remediation planning.", [["AI System Inventory", "Step 1: Create a comprehensive inventory of all AI systems in use. For each system document: purpose, provider, risk category, data processed, users, and deployment date. Template provided."], ["Risk Classification", "Step 2: Classify each AI system by EU AI Act risk level: Unacceptable (prohibited), High Risk (Articles 6-7 requirements), Limited Risk (transparency obligations), and Minimal Risk (no specific requirements)."], ["Gap Analysis", "Step 3: For high-risk systems, assess compliance with: risk management system (Article 9), data governance (Article 10), technical documentation (Article 11), record-keeping (Article 12), transparency (Article 13), human oversight (Article 14), and accuracy (Article 15)."], ["Remediation Plan", "Step 4: Create a prioritized remediation plan for identified gaps. Template includes: gap description, severity, responsible party, remediation action, timeline, cost estimate, and verification method."]]),
    r("ai-incident-response-playbook", "AI Incident Response Playbook", "guide", "Step-by-step playbook for responding to AI security incidents. Detection, containment, investigation, and communication procedures.", [["Detection & Classification", "Detect AI incidents through: automated monitoring alerts, user reports, audit log anomalies, and external notifications. Classify by severity: Critical (data breach confirmed), High (data exposure possible), Medium (policy violation), Low (anomaly detected)."], ["Containment", "Immediate containment actions: revoke affected user access, block affected model endpoint, preserve audit logs, engage incident response team. For data breaches: activate breach notification procedures."], ["Investigation", "Investigation procedures: review audit trail for affected period, identify scope of data exposure, determine root cause, assess regulatory notification requirements, interview affected users if needed."], ["Recovery & Lessons", "Recovery: remediate root cause, update guardrail rules, restore access with enhanced controls, communicate resolution. Post-incident: conduct blameless retrospective, update playbook, brief leadership, file regulatory notifications if required."]]),
    r("soc2-ai-controls-mapping", "SOC 2 Controls Mapping for AI Platforms", "guide", "Map SOC 2 Trust Service Criteria to AI platform controls. Comprehensive mapping for Type I and Type II audits.", [["Security (CC) Mapping", "Map AI controls to Common Criteria: CC6.1 (logical access), CC6.2 (credentials), CC6.3 (access removal), CC6.6 (external threats), CC6.7 (transmission security), CC6.8 (unauthorized changes), CC7.1 (monitoring), CC7.2 (anomaly detection)."], ["Availability (A) Mapping", "Map to Availability criteria: A1.1 (capacity management), A1.2 (environmental protections), A1.3 (recovery). AI platforms should demonstrate: multi-provider failover, auto-scaling, and disaster recovery procedures."], ["Confidentiality (C) Mapping", "Map to Confidentiality criteria: C1.1 (identification of confidential info), C1.2 (disposal). PII redaction and zero-history architecture directly satisfy many confidentiality requirements."], ["Processing Integrity (PI) Mapping", "Map to Processing Integrity criteria: PI1.1 (quality objectives), PI1.2 (system inputs), PI1.3 (system processing), PI1.4 (system output), PI1.5 (storage). Guardrails and audit logs demonstrate processing integrity controls."]]),
    r("ai-training-curriculum", "Enterprise AI Training Curriculum", "toolkit", "Complete training curriculum for enterprise AI rollout. Role-specific modules, hands-on exercises, and certification tracks.", [["Module 1: AI Foundations (All Roles)", "What is generative AI, how LLMs work (simplified), AI capabilities and limitations, responsible AI principles, and your organization's AI policy. Duration: 1 hour."], ["Module 2: Platform Training (All Roles)", "Platform walkthrough, SSO login, model selection, prompt basics, file upload and analysis, presets, and common use cases for your role. Duration: 1 hour with hands-on."], ["Module 3: Advanced Usage (Power Users)", "Advanced prompting techniques, chain-of-thought reasoning, multi-step workflows, API access, custom presets, and department-specific best practices. Duration: 2 hours."], ["Module 4: Governance Training (Admins)", "Department setup and management, budget configuration, guardrail customization, audit log review, compliance reporting, user management, and incident response. Duration: 3 hours."]]),
    r("ai-roi-calculator", "Enterprise AI ROI Calculator", "toolkit", "Calculate and project ROI from enterprise AI deployment. Input your metrics and get projected returns across multiple dimensions.", [["Productivity ROI", "Input: number of knowledge workers, average hours per week on AI-augmentable tasks, expected time savings percentage (benchmark: 25-40%). Formula: Workers × Hours × Savings% × Hourly Cost × 52 weeks."], ["Cost Avoidance ROI", "Input: current number of AI subscriptions, per-seat costs, estimated shadow AI usage. Formula: consolidation savings + shadow AI risk prevention (breach probability × average breach cost)."], ["Governance ROI", "Input: regulatory exposure, current compliance gaps, audit preparation time. Formula: fine avoidance probability × potential fine + audit time savings × hourly cost + insurance premium reduction."], ["Total ROI Projection", "Combine all dimensions for total projected ROI. Typical enterprise results: 3-8x ROI in year one, rising to 5-12x by year two as adoption increases. Break-even typically occurs within 45-60 days."]]),
    r("ai-policy-communication-kit", "AI Policy Communication Kit", "toolkit", "Internal communication templates for AI governance rollout. Executive announcements, department briefings, FAQ documents, and training invitations.", [["Executive Announcement", "Email template for CEO/CIO announcing AI governance program: vision, why now, what changes, timeline, and call to action. Tone: positive, forward-looking, empowering."], ["Department Briefings", "Presentation template for department-level briefings: what AI governance means for your team, new tools available, what's changing, what's not changing, Q&A preparation."], ["Employee FAQ", "30-question FAQ covering: What AI tools can I use? What happens to my ChatGPT history? Will AI replace my job? How do I get help? What data can I share? Is my usage monitored?"], ["Training Calendar", "Communication templates for mandatory and optional training sessions with calendar invites, reminder emails, and post-training survey links."]]),
    r("ai-maturity-assessment-tool", "AI Maturity Assessment Tool", "toolkit", "50-question self-assessment to evaluate your organization's AI maturity across five dimensions. Scoring guide and improvement roadmap included.", [["Strategy Dimension (10 questions)", "Assess: executive sponsorship, AI vision clarity, strategic alignment, investment commitment, competitive positioning, innovation culture, partnership strategy, metrics definition, roadmap existence, and board engagement."], ["Governance Dimension (10 questions)", "Assess: policy existence, technical controls, compliance mapping, audit readiness, risk management, ethical framework, incident response, vendor management, training program, and organizational structure."], ["Technology Dimension (10 questions)", "Assess: platform selection, model diversity, security controls, integration depth, scalability, observability, automation, knowledge management, development capabilities, and infrastructure readiness."], ["Talent & Operations (20 questions)", "Assess talent: AI skills inventory, training investment, champions program, hiring strategy, retention programs, org design, change management, user adoption, support model, and continuous improvement. Assess operations: deployment processes, monitoring, optimization, cost management, quality assurance, documentation, collaboration tools, feedback loops, innovation pipeline, and measurement."]]),
    r("comparison-matrix-ai-platforms", "AI Platform Comparison Matrix", "template", "Side-by-side comparison matrix of enterprise AI governance platforms. 100+ criteria across security, compliance, cost, and capabilities.", [["Security Features Matrix", "Compare platforms on: zero-history architecture, PII redaction layers, guardrail types, DLP capabilities, encryption standards, on-prem option, air-gap support, SSO protocols, MFA options, and penetration testing."], ["Compliance Features Matrix", "Compare on: SOC 2 certification, HIPAA readiness, GDPR compliance, EU AI Act alignment, NIST AI RMF coverage, audit log format, export capabilities, retention controls, and regulatory reporting."], ["Capability Features Matrix", "Compare on: number of models, model routing, RAG support, file analysis, web search, code execution, multimodal, API access, SDK availability, and custom model support."], ["Cost & Operations Matrix", "Compare on: pricing model, cost normalization, budget controls, billing granularity, support tiers, SLA commitments, documentation, community, professional services, and roadmap transparency."]]),
    r("quarterly-ai-review-template", "Quarterly AI Governance Review Template", "template", "Structured template for quarterly AI governance reviews. Metrics, trends, issues, and recommendations for leadership presentation.", [["Executive Summary", "Template for one-page executive summary: key metrics vs. targets, notable achievements, emerging risks, strategic recommendations, and budget outlook. Designed for board and C-suite consumption."], ["Usage Analytics", "Charts and tables template for: total interactions trend, active users by department, model usage distribution, peak usage patterns, top use cases, and adoption curve analysis."], ["Security & Compliance", "Template for: PII detection stats, policy violations by category, incident report summary, compliance audit findings, guardrail effectiveness metrics, and security improvement trending."], ["Financial Review", "Template for: total AI costs vs. budget, department-level spending, cost per user trending, ROI calculations, vendor cost comparison, and next quarter budget recommendations."]]),
    r("ai-risk-register-template", "AI Risk Register Template", "template", "Comprehensive AI risk register with pre-populated enterprise AI risks. Risk scoring, ownership assignment, and mitigation tracking.", [["Pre-Populated Risks", "40 pre-identified AI risks across categories: data security, compliance, operational, reputational, financial, and strategic. Each risk includes: description, likelihood score, impact score, and suggested mitigations."], ["Scoring Methodology", "Risk scoring matrix: Likelihood (1-5) × Impact (1-5) = Risk Score (1-25). Color coding: Green (1-6), Yellow (7-12), Orange (13-18), Red (19-25). Assessment frequency and escalation thresholds defined."], ["Mitigation Tracking", "For each risk: mitigation actions, responsible owner, target completion date, current status, residual risk score, and review cadence. Links to supporting controls and governance platform configurations."], ["Reporting Dashboard", "Template for monthly risk dashboard: top 10 risks by score, new risks identified, risks resolved, risk trend over time, and upcoming mitigation milestones."]]),
    r("ai-governance-kpi-dashboard", "AI Governance KPI Dashboard Guide", "guide", "Design and build your AI governance KPI dashboard. Metrics selection, data sources, visualization, and stakeholder views.", [["Metric Selection Framework", "Select KPIs using the SMART framework: Specific (what exactly are we measuring), Measurable (can we quantify it), Actionable (can we influence it), Relevant (does it matter), Time-bound (what's the cadence)."], ["Core KPIs", "15 essential AI governance KPIs: daily active users, queries per user, PII detections, policy violations, cost per department, budget utilization, model distribution, guardrail trigger rate, mean time to detect, adoption rate, user satisfaction, ROI, audit readiness score, incident count, and training completion."], ["Data Sources", "Map each KPI to its data source: platform API, audit log exports, user surveys, financial systems, HR systems, and manual inputs. Include API endpoints and query templates."], ["Stakeholder Views", "Four dashboard views: CISO (security-focused), CFO (cost-focused), CIO (adoption-focused), Compliance (regulatory-focused). Each view shows the 5-7 most relevant KPIs with appropriate visualizations."]]),
    r("ai-deployment-runbook", "Enterprise AI Deployment Runbook", "guide", "Step-by-step runbook for deploying enterprise AI platforms. Pre-deployment, deployment day, post-deployment, and steady-state operations.", [["Pre-Deployment (2 weeks)", "Complete before deployment: finalize vendor selection, execute contracts, configure SSO integration, define department structure, set initial budgets, configure guardrails, create acceptable use policy, prepare training materials, and identify pilot group."], ["Deployment Day", "Deployment checklist: enable SSO connection, create departments and invite department heads, configure budget caps, activate guardrails, onboard pilot users, verify audit logging, test PII redaction, validate cost tracking, and confirm alerting."], ["Post-Deployment (4 weeks)", "Week 1-2: monitor pilot group, gather feedback, tune guardrails, adjust budgets. Week 3-4: expand to additional departments, conduct training sessions, review audit logs, optimize model routing, and address support tickets."], ["Steady-State Operations", "Ongoing operations: daily security monitoring, weekly usage review, monthly budget review, quarterly governance review, annual risk assessment, continuous guardrail tuning, regular access reviews, and vendor relationship management."]]),
    r("prompt-library-enterprise", "Enterprise Prompt Library: 100+ Templates", "toolkit", "Curated prompt templates for enterprise use cases across engineering, marketing, legal, HR, finance, and operations.", [["Engineering Prompts (25)", "Templates for: code review, debugging, documentation generation, test writing, architecture design, SQL optimization, API design, security review, performance analysis, refactoring, migration planning, and technical specification writing."], ["Marketing Prompts (25)", "Templates for: blog post outlines, social media content, email campaigns, ad copy, product descriptions, press releases, case study drafts, SEO content, landing page copy, and content calendar planning."], ["Legal & Compliance (25)", "Templates for: contract clause analysis, regulatory research, policy drafting, compliance gap analysis, risk assessment summaries, incident reports, audit preparation, and legal memo outlines."], ["Business Operations (25)", "Templates for: meeting summaries, project status reports, budget analysis, strategic planning, competitive analysis, process documentation, training materials, FAQ generation, and presentation outlines."]]),
    r("ai-security-architecture-blueprint", "AI Security Architecture Blueprint", "guide", "Reference security architecture for enterprise AI deployments. Network, application, data, and identity layers with implementation guidance.", [["Architecture Overview", "Four-layer security architecture: perimeter (network controls), application (AI safety layer), data (DLP and encryption), and identity (access management). Each layer provides defense-in-depth with independent controls."], ["Network Layer Design", "Implement: TLS 1.3 termination at load balancer, Web Application Firewall (WAF) rules for AI traffic, private endpoints for on-premises integration, egress filtering to approved AI providers only, and DDoS protection."], ["Application Layer Design", "Deploy AI safety layer with: input validation pipeline (rule-based → semantic analysis), output screening pipeline (content safety → brand safety), rate limiting engine, session management, and comprehensive request/response logging."], ["Identity Layer Design", "Implement: SAML 2.0/OIDC for SSO, MFA enforcement via identity provider, three-tier RBAC (admin → department head → user), JWT-based session management, API key governance with rotation policies, and automated provisioning/deprovisioning."]]),
    r("ai-ethics-framework-template", "AI Ethics Framework Template", "template", "Build your organization's AI ethics framework. Principles, governance structure, review process, and accountability mechanisms.", [["Ethics Principles", "Define 5-7 core AI ethics principles for your organization. Templates provided for: fairness, transparency, accountability, privacy, safety, human oversight, and environmental responsibility. Each principle includes definition, scope, and operationalization guidance."], ["Governance Structure", "Template for AI ethics governance: ethics committee charter, membership criteria, decision-making authority, escalation procedures, reporting cadence, and relationship to existing governance bodies."], ["Ethics Review Process", "Process template for AI ethics reviews: when reviews are triggered, review criteria checklist, documentation requirements, approval workflows, and exception handling. Includes templates for ethics review reports."], ["Accountability Framework", "Define accountability: role-specific AI ethics responsibilities, training requirements, performance criteria, reporting obligations, and consequences for ethics violations. Maps to existing HR and compliance frameworks."]]),
    r("data-sovereignty-playbook", "Data Sovereignty Playbook for AI", "guide", "Navigate data sovereignty requirements for global AI deployments. Regional regulations, deployment strategies, and compliance controls.", [["Global Regulatory Landscape", "Overview of data sovereignty requirements by region: EU (GDPR), US (state laws), China (PIPL, DSL), India (DPDPA), Brazil (LGPD), Japan (APPI), South Korea (PIPA), and Australia (Privacy Act). Key requirements and cross-border transfer rules for each."], ["AI-Specific Considerations", "AI adds complexity to data sovereignty: Where are prompts processed? Where do models run? Who has access to interaction data? How are cross-border API calls handled? Map each question to regulatory requirements."], ["Deployment Strategies", "Three strategies for multi-region compliance: regional deployment (separate instances per region), data routing (route queries to region-specific endpoints), and on-premises (local deployment for strictest requirements). Pros, cons, and cost comparison."], ["Implementation Checklist", "25-point data sovereignty checklist: identify applicable regulations, map data flows, classify data by sensitivity, configure data residency controls, document cross-border transfers, implement SCCs where needed, audit data processing locations, and maintain compliance evidence."]]),
];
